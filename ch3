import  matplotlib.pyplot as plt
import  tensorflow as tf
from tensorflow import keras
import numpy as np
from keras.datasets import  mnist

img_rows = 28
img_cols = 28
channels = 1

# Input image dimensions
img_shape = (img_rows, img_cols, channels)

# Size of the noise vector, used as input to the Generator
z_dim = 100

def build_generator(img_shape,z_dim):

    inputs = keras.Input(shape=(z_dim,))

    x = keras.layers.Dense(128)(inputs)

    x = keras.layers.LeakyReLU(alpha=0.01)(x)

    x = keras.layers.Dense(28*28*1,activation='tanh')(x)

    outputs = keras.layers.Reshape(img_shape)(x)

    model = keras.models.Model(inputs=inputs,outputs=outputs)

    return model

def build_discriminator(img_shape):

    input = keras.Input(shape=img_shape)

    x = keras.layers.Flatten()(input)

    x = keras.layers.Dense(128)(x)

    x = keras.layers.LeakyReLU(alpha=0.01)(x)

    output = keras.layers.Dense(1,activation='sigmoid')(x)

    model = keras.models.Model(inputs=input,outputs=output)

    return model

def build_gan(generator,discriminator):
    model = keras.Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

discriminator = build_discriminator(img_shape)

discriminator.compile(loss='binary_crossentropy',
                      optimizer=keras.optimizers.Adam(),
                      metrics=['accuracy'])

generator = build_generator(img_shape,z_dim)

discriminator.trainable = False

gan = build_gan(generator,discriminator)
gan.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam())

print("===generator.summary()===")
generator.summary()
print("===discriminator.summary()===")
discriminator.summary()
print("===gan.summary()===")
gan.summary()

losses = []
accuracies = []
iteration_checkpoints = []

def train(iterations, batch_size, sample_interval):
    # Load the MNIST dataset
    (X_train, _), (_, _) = mnist.load_data()
    # Rescale [0, 255] grayscale pixel values to [-1, 1]
    X_train = X_train / 127.5 - 1.0
    #增加維度(channel)
    X_train = np.expand_dims(X_train, axis=3)

    # Labels for real images: all ones
    real = np.ones((batch_size, 1))

    # Labels for fake images: all zeros
    fake = np.zeros((batch_size, 1))

    for iteration in range(iterations):
        # -------------------------
        #  Train the Discriminator
        # -------------------------

        # Get a random batch of real images
        idx = np.random.randint(0, X_train.shape[0], batch_size)
        imgs = X_train[idx]

        # Generate a batch of fake images
        z = np.random.normal(0, 1, (batch_size, 100))
        gen_imgs = generator.predict(z)


